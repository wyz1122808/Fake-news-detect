{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries\n"
      ],
      "metadata": {
        "id": "51doe-4Hn_VE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "seshLZepnmzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d718ce-b50d-47ad-d9fc-c3aa515559c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1p3Y2ANrNqFktLfwdgfACvNmPL1xmvPgk\n",
            "To: /content/fake_or_real_news.csv\n",
            "100% 31.4M/31.4M [00:00<00:00, 110MB/s] \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import drive\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1p3Y2ANrNqFktLfwdgfACvNmPL1xmvPgk -O ./fake_or_real_news.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the necessary NLTK data and stopwords"
      ],
      "metadata": {
        "id": "YZzr2JYooC96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMJj6GE4oDNQ",
        "outputId": "5b81b2b3-5018-4d9c-c437-b12b0eb20d73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "octxVG4OoDjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading the dataset...\")\n",
        "\n",
        "df = pd.read_csv('./fake_or_real_news.csv', encoding='utf-8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yz_FGMeoH6H",
        "outputId": "0a631486-8b4d-4379-9350-d2a8f3577319"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "V_5NAoWvoIkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nChecking for missing values in the dataset...\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxFP8_csoI3y",
        "outputId": "5ac0c148-a001-449d-a9c1-771e29bc568a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking for missing values in the dataset...\n",
            "Unnamed: 0    0\n",
            "title         0\n",
            "text          0\n",
            "label         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop rows with missing values"
      ],
      "metadata": {
        "id": "Wfxsd36AoJMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "print(\"\\nDropped rows with missing values (if any).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HYfpLEXoVhg",
        "outputId": "a9be85e0-9cab-4f11-8e8e-1a2853ea2a1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dropped rows with missing values (if any).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "vPcsj5xLoV2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPreprocessing the text data...\")\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPJzaYB5oWGe",
        "outputId": "dae63244-619a-4155-9e32-504c02dd06f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessing the text data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lp96QhntoWTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    # Remove punctuations and numbers\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords and stem the words\n",
        "    text = [stemmer.stem(word) for word in text.split() if word not in set(stopwords.words('english'))]\n",
        "\n",
        "    return ' '.join(text)\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(preprocess)\n",
        "print(\"Text data preprocessing complete.\")"
      ],
      "metadata": {
        "id": "nIaGq5Q2ob6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaea26ad-fe02-4e79-f307-ff77be1295e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text data preprocessing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction using TF-IDF"
      ],
      "metadata": {
        "id": "i3HBK-8VocUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nExtracting features using TF-IDF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.7, max_features=5000)\n",
        "X = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n",
        "y = df['label']\n",
        "print(\"Feature extraction complete.\")"
      ],
      "metadata": {
        "id": "1STJq9z-ocjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47dbdda-7fb8-4848-9725-f291ce5eaf69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting features using TF-IDF...\n",
            "Feature extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "n86BewdPosTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSplitting the data into training and test sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "print(\"Training the Logistic Regression model...\")\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "id": "hzv6xMUHossv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af375388-9d2d-43e9-c7b8-b0b885414649"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Splitting the data into training and test sets...\n",
            "Training the Logistic Regression model...\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "5mCZgP5yozCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEvaluating the model...\")\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "FESJZvu4ozSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ec0e37-bfce-4369-c283-f3c61e736c03"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating the model...\n",
            "Accuracy: 91.16%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.91      0.91      0.91       615\n",
            "        REAL       0.92      0.91      0.91       652\n",
            "\n",
            "    accuracy                           0.91      1267\n",
            "   macro avg       0.91      0.91      0.91      1267\n",
            "weighted avg       0.91      0.91      0.91      1267\n",
            "\n"
          ]
        }
      ]
    }
  ]
}